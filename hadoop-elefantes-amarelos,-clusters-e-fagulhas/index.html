<!DOCTYPE html>
<html lang="pt-BR" class="no-js">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    
    

    
    

    
    

    
    

    <title>Hadoop: Elefantes amarelos, Clusters e Fagulhas | A Sétima Nébula</title>
    <meta name="description" content="A Sétima Nébula é um blog contendo artigos sobre temas relacionados à Engenharia de Dados, escritos de uma maneira simples e intuitiva.">
    
        <meta name="keywords" content="hadoop, bigdata, spark">
    

    <!-- Social: Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Hadoop: Elefantes amarelos, Clusters e Fagulhas | A Sétima Nébula">
    <meta name="twitter:description" content="A Sétima Nébula é um blog contendo artigos sobre temas relacionados à Engenharia de Dados, escritos de uma maneira simples e intuitiva.">

    
        <meta property="twitter:image" content="https://i.imgur.com/mEgc9jG.jpeg">
    
    
    

    <!-- Social: Facebook / Open Graph -->
    <meta property="og:url" content="/nebula/hadoop-elefantes-amarelos,-clusters-e-fagulhas/">
    <meta property="og:title" content="Hadoop: Elefantes amarelos, Clusters e Fagulhas | A Sétima Nébula">
    <meta property="og:image" content="https://i.imgur.com/mEgc9jG.jpeg">
    <meta property="og:description" content="A Sétima Nébula é um blog contendo artigos sobre temas relacionados à Engenharia de Dados, escritos de uma maneira simples e intuitiva.">
    <meta property="og:site_name" content="A Sétima Nébula">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/nebula/favicon.ico" type="image/x-icon" />
    
    <!-- Apple Touch Icons -->
    <link rel="apple-touch-icon" href="/nebula/assets/img/icons/apple-touch-icon.png" />
    <link rel="apple-touch-icon" sizes="57x57" href="/assets/img/icons/apple-touch-icon-57x57.png" />
    <link rel="apple-touch-icon" sizes="72x72" href="/assets/img/icons/apple-touch-icon-72x72.png" />
    <link rel="apple-touch-icon" sizes="114x114" href="/assets/img/icons/apple-touch-icon-114x114.png" />
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/img/icons/apple-touch-icon-144x144.png" />
    <link rel="apple-touch-icon" sizes="60x60" href="/assets/img/icons/apple-touch-icon-60x60.png" />
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/img/icons/apple-touch-icon-120x120.png" />
    <link rel="apple-touch-icon" sizes="76x76" href="/assets/img/icons/apple-touch-icon-76x76.png" />
    <link rel="apple-touch-icon" sizes="152x152" href="/assets/img/icons/apple-touch-icon-152x152.png" />

    <!-- Windows 8 Tile Icons -->
    <meta name="application-name" content="A Sétima Nébula">
    <meta name="msapplication-TileColor" content="#141414">
    <meta name="msapplication-square70x70logo" content="smalltile.png" />
    <meta name="msapplication-square150x150logo" content="mediumtile.png" />
    <meta name="msapplication-wide310x150logo" content="widetile.png" />
    <meta name="msapplication-square310x310logo" content="largetile.png" />
    
    <!-- Android Lolipop Theme Color -->
    <meta name="theme-color" content="#141414">

    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Titillium+Web:300,400,700" rel="stylesheet">

    <link rel="stylesheet" href="/nebula/assets/css/styles.css">
    <link rel="canonical" href="/nebula/hadoop-elefantes-amarelos,-clusters-e-fagulhas/">
    <link rel="alternate" type="application/rss+xml" title="A Sétima Nébula" href="/nebula/feed.xml" />

    <!-- Include extra styles -->
    

    <!-- JavaScript enabled/disabled -->
    <script>
        document.querySelector('html').classList.remove('no-js');
    </script>
</head>

    <body class="has-push-menu">
        





        <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" display="none" version="1.1"><defs><symbol id="icon-menu" viewBox="0 0 1024 1024"><path class="path1" d="M128 213.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 725.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5zM128 469.333h768q17.667 0 30.167 12.5t12.5 30.167-12.5 30.167-30.167 12.5h-768q-17.667 0-30.167-12.5t-12.5-30.167 12.5-30.167 30.167-12.5z"/></symbol><symbol id="icon-search" viewBox="0 0 951 1024"><path class="path1" d="M658.286 475.429q0-105.714-75.143-180.857t-180.857-75.143-180.857 75.143-75.143 180.857 75.143 180.857 180.857 75.143 180.857-75.143 75.143-180.857zM950.857 950.857q0 29.714-21.714 51.429t-51.429 21.714q-30.857 0-51.429-21.714l-196-195.429q-102.286 70.857-228 70.857-81.714 0-156.286-31.714t-128.571-85.714-85.714-128.571-31.714-156.286 31.714-156.286 85.714-128.571 128.571-85.714 156.286-31.714 156.286 31.714 128.571 85.714 85.714 128.571 31.714 156.286q0 125.714-70.857 228l196 196q21.143 21.143 21.143 51.429z"/></symbol><symbol id="icon-close" viewBox="0 0 1000 1000"><path d="M969.8,870.3c27,27.7,27,71.8,0,99.1C955.7,983,937.9,990,920,990c-17.9,0-35.7-7-49.7-20.7L500,599L129.6,969.4C115.6,983,97.8,990,79.9,990s-35.7-7-49.7-20.7c-27-27.3-27-71.4,0-99.1L400.9,500L30.3,129.3c-27-27.3-27-71.4,0-99.1c27.3-27,71.8-27,99.4,0L500,400.9L870.4,30.2c27.7-27,71.8-27,99.4,0c27,27.7,27,71.8,0,99.1L599.1,500L969.8,870.3z"/></symbol><symbol id="icon-twitter" viewBox="0 0 951 1024"><path class="path1" d="M925.714 233.143q-38.286 56-92.571 95.429 0.571 8 0.571 24 0 74.286-21.714 148.286t-66 142-105.429 120.286-147.429 83.429-184.571 31.143q-154.857 0-283.429-82.857 20 2.286 44.571 2.286 128.571 0 229.143-78.857-60-1.143-107.429-36.857t-65.143-91.143q18.857 2.857 34.857 2.857 24.571 0 48.571-6.286-64-13.143-106-63.714t-42-117.429v-2.286q38.857 21.714 83.429 23.429-37.714-25.143-60-65.714t-22.286-88q0-50.286 25.143-93.143 69.143 85.143 168.286 136.286t212.286 56.857q-4.571-21.714-4.571-42.286 0-76.571 54-130.571t130.571-54q80 0 134.857 58.286 62.286-12 117.143-44.571-21.143 65.714-81.143 101.714 53.143-5.714 106.286-28.571z"/></symbol><symbol id="icon-facebook" viewBox="0 0 585 1024"><path class="path1" d="M548 6.857v150.857h-89.714q-49.143 0-66.286 20.571t-17.143 61.714v108h167.429l-22.286 169.143h-145.143v433.714h-174.857v-433.714h-145.714v-169.143h145.714v-124.571q0-106.286 59.429-164.857t158.286-58.571q84 0 130.286 6.857z"/></symbol><symbol id="icon-clock" viewBox="0 0 1000 1000"><path d="M500,10C229.8,10,10,229.8,10,500c0,270.2,219.8,490,490,490c270.2,0,490-219.8,490-490C990,229.8,770.2,10,500,10z M500,910.2c-226.2,0-410.2-184-410.2-410.2c0-226.2,184-410.2,410.2-410.2c226.2,0,410.2,184,410.2,410.2C910.2,726.1,726.2,910.2,500,910.2z M753.1,374c8.2,11.9,5.2,28.1-6.6,36.3L509.9,573.7c-4.4,3.1-9.6,4.6-14.8,4.6c-4.1,0-8.3-1-12.1-3c-8.6-4.5-14-13.4-14-23.1V202.5c0-14.4,11.7-26.1,26.1-26.1c14.4,0,26.1,11.7,26.1,26.1v300l195.6-135.1C728.7,359.2,744.9,362.1,753.1,374z"/></symbol><symbol id="icon-calendar" viewBox="0 0 1000 1000"><path d="M920,500v420H80V500H920 M990,430H10v490c0,38.7,31.3,70,70,70h840c38.7,0,70-31.3,70-70V430L990,430z"/><path d="M850,80v105c0,57.9-47.2,105-105,105c-58,0-105-47.1-105-105V80H360v105c0,57.9-47.2,105-105,105c-58,0-105-47.1-105-105V80C72.8,80,10,142.7,10,220v140h980V220C990,142.7,927.2,80,850,80z"/><path d="M255,10c-19.3,0-35,15.8-35,35v140c0,19.2,15.7,35,35,35c19.3,0,35-15.8,35-35V45C290,25.8,274.3,10,255,10z"/><path d="M745,10c-19.3,0-35,15.8-35,35v140c0,19.2,15.7,35,35,35c19.3,0,35-15.8,35-35V45C780,25.8,764.3,10,745,10z"/></symbol><symbol id="icon-github" viewBox="0 0 12 14"><path d="M6 1q1.633 0 3.012 0.805t2.184 2.184 0.805 3.012q0 1.961-1.145 3.527t-2.957 2.168q-0.211 0.039-0.312-0.055t-0.102-0.234q0-0.023 0.004-0.598t0.004-1.051q0-0.758-0.406-1.109 0.445-0.047 0.801-0.141t0.734-0.305 0.633-0.52 0.414-0.82 0.16-1.176q0-0.93-0.617-1.609 0.289-0.711-0.062-1.594-0.219-0.070-0.633 0.086t-0.719 0.344l-0.297 0.187q-0.727-0.203-1.5-0.203t-1.5 0.203q-0.125-0.086-0.332-0.211t-0.652-0.301-0.664-0.105q-0.352 0.883-0.062 1.594-0.617 0.68-0.617 1.609 0 0.664 0.16 1.172t0.41 0.82 0.629 0.523 0.734 0.305 0.801 0.141q-0.305 0.281-0.383 0.805-0.164 0.078-0.352 0.117t-0.445 0.039-0.512-0.168-0.434-0.488q-0.148-0.25-0.379-0.406t-0.387-0.187l-0.156-0.023q-0.164 0-0.227 0.035t-0.039 0.090 0.070 0.109 0.102 0.094l0.055 0.039q0.172 0.078 0.34 0.297t0.246 0.398l0.078 0.18q0.102 0.297 0.344 0.48t0.523 0.234 0.543 0.055 0.434-0.027l0.18-0.031q0 0.297 0.004 0.691t0.004 0.426q0 0.141-0.102 0.234t-0.312 0.055q-1.812-0.602-2.957-2.168t-1.145-3.527q0-1.633 0.805-3.012t2.184-2.184 3.012-0.805zM2.273 9.617q0.023-0.055-0.055-0.094-0.078-0.023-0.102 0.016-0.023 0.055 0.055 0.094 0.070 0.047 0.102-0.016zM2.516 9.883q0.055-0.039-0.016-0.125-0.078-0.070-0.125-0.023-0.055 0.039 0.016 0.125 0.078 0.078 0.125 0.023zM2.75 10.234q0.070-0.055 0-0.148-0.062-0.102-0.133-0.047-0.070 0.039 0 0.141t0.133 0.055zM3.078 10.562q0.062-0.062-0.031-0.148-0.094-0.094-0.156-0.023-0.070 0.062 0.031 0.148 0.094 0.094 0.156 0.023zM3.523 10.758q0.023-0.086-0.102-0.125-0.117-0.031-0.148 0.055t0.102 0.117q0.117 0.047 0.148-0.047zM4.016 10.797q0-0.102-0.133-0.086-0.125 0-0.125 0.086 0 0.102 0.133 0.086 0.125 0 0.125-0.086zM4.469 10.719q-0.016-0.086-0.141-0.070-0.125 0.023-0.109 0.117t0.141 0.062 0.109-0.109z"></path></symbol><symbol id="icon-medium" viewBox="0 0 1000 1000"><path d="M336.5,240.2v641.5c0,9.1-2.3,16.9-6.8,23.2s-11.2,9.6-20,9.6c-6.2,0-12.2-1.5-18-4.4L37.3,782.7c-7.7-3.6-14.1-9.8-19.4-18.3S10,747.4,10,739V115.5c0-7.3,1.8-13.5,5.5-18.6c3.6-5.1,8.9-7.7,15.9-7.7c5.1,0,13.1,2.7,24.1,8.2l279.5,140C335.9,238.6,336.5,239.5,336.5,240.2L336.5,240.2z M371.5,295.5l292,473.6l-292-145.5V295.5z M990,305.3v576.4c0,9.1-2.6,16.5-7.7,22.1c-5.1,5.7-12,8.5-20.8,8.5s-17.3-2.4-25.7-7.1L694.7,784.9L990,305.3z M988.4,239.7c0,1.1-46.8,77.6-140.3,229.4C754.6,621,699.8,709.8,683.8,735.7L470.5,389l177.2-288.2c6.2-10.2,15.7-15.3,28.4-15.3c5.1,0,9.8,1.1,14.2,3.3l295.9,147.7C987.6,237.1,988.4,238.2,988.4,239.7L988.4,239.7z"/></symbol><symbol id="icon-instagram" viewBox="0 0 489.84 489.84"><path d="M249.62,50.46c65.4,0,73.14.25,99,1.43C372.47,53,385.44,57,394.07,60.32a75.88,75.88,0,0,1,28.16,18.32,75.88,75.88,0,0,1,18.32,28.16c3.35,8.63,7.34,21.6,8.43,45.48,1.18,25.83,1.43,33.57,1.43,99s-0.25,73.14-1.43,99c-1.09,23.88-5.08,36.85-8.43,45.48a81.11,81.11,0,0,1-46.48,46.48c-8.63,3.35-21.6,7.34-45.48,8.43-25.82,1.18-33.57,1.43-99,1.43s-73.15-.25-99-1.43c-23.88-1.09-36.85-5.08-45.48-8.43A75.88,75.88,0,0,1,77,423.86,75.88,75.88,0,0,1,58.69,395.7c-3.35-8.63-7.34-21.6-8.43-45.48-1.18-25.83-1.43-33.57-1.43-99s0.25-73.14,1.43-99c1.09-23.88,5.08-36.85,8.43-45.48A75.88,75.88,0,0,1,77,78.64a75.88,75.88,0,0,1,28.16-18.32c8.63-3.35,21.6-7.34,45.48-8.43,25.83-1.18,33.57-1.43,99-1.43m0-44.13c-66.52,0-74.86.28-101,1.47s-43.87,5.33-59.45,11.38A120.06,120.06,0,0,0,45.81,47.44,120.06,120.06,0,0,0,17.56,90.82C11.5,106.4,7.36,124.2,6.17,150.27s-1.47,34.46-1.47,101,0.28,74.86,1.47,101,5.33,43.87,11.38,59.45a120.06,120.06,0,0,0,28.25,43.38,120.06,120.06,0,0,0,43.38,28.25c15.58,6.05,33.38,10.19,59.45,11.38s34.46,1.47,101,1.47,74.86-.28,101-1.47,43.87-5.33,59.45-11.38a125.24,125.24,0,0,0,71.63-71.63c6.05-15.58,10.19-33.38,11.38-59.45s1.47-34.46,1.47-101-0.28-74.86-1.47-101-5.33-43.87-11.38-59.45a120.06,120.06,0,0,0-28.25-43.38,120.06,120.06,0,0,0-43.38-28.25C394.47,13.13,376.67,9,350.6,7.8s-34.46-1.47-101-1.47h0Z" transform="translate(-4.7 -6.33)" /><path d="M249.62,125.48A125.77,125.77,0,1,0,375.39,251.25,125.77,125.77,0,0,0,249.62,125.48Zm0,207.41a81.64,81.64,0,1,1,81.64-81.64A81.64,81.64,0,0,1,249.62,332.89Z" transform="translate(-4.7 -6.33)"/><circle cx="375.66" cy="114.18" r="29.39" /></symbol><symbol id="icon-linkedin" viewBox="0 0 12 14"><path d="M2.727 4.883v7.742h-2.578v-7.742h2.578zM2.891 2.492q0.008 0.57-0.395 0.953t-1.059 0.383h-0.016q-0.641 0-1.031-0.383t-0.391-0.953q0-0.578 0.402-0.957t1.051-0.379 1.039 0.379 0.398 0.957zM12 8.187v4.437h-2.57v-4.141q0-0.82-0.316-1.285t-0.988-0.465q-0.492 0-0.824 0.27t-0.496 0.668q-0.086 0.234-0.086 0.633v4.32h-2.57q0.016-3.117 0.016-5.055t-0.008-2.313l-0.008-0.375h2.57v1.125h-0.016q0.156-0.25 0.32-0.438t0.441-0.406 0.68-0.34 0.895-0.121q1.336 0 2.148 0.887t0.813 2.598z"></path></symbol><symbol id="icon-heart" viewBox="0 0 34 30"><path d="M17,29.7 L16.4,29.2 C3.5,18.7 0,15 0,9 C0,4 4,0 9,0 C13.1,0 15.4,2.3 17,4.1 C18.6,2.3 20.9,0 25,0 C30,0 34,4 34,9 C34,15 30.5,18.7 17.6,29.2 L17,29.7 Z M9,2 C5.1,2 2,5.1 2,9 C2,14.1 5.2,17.5 17,27.1 C28.8,17.5 32,14.1 32,9 C32,5.1 28.9,2 25,2 C21.5,2 19.6,4.1 18.1,5.8 L17,7.1 L15.9,5.8 C14.4,4.1 12.5,2 9,2 Z" id="Shape"></path></symbol><symbol id="icon-arrow-right" viewBox="0 0 25.452 25.452"><path d="M4.471,24.929v-2.004l12.409-9.788c0.122-0.101,0.195-0.251,0.195-0.411c0-0.156-0.073-0.31-0.195-0.409L4.471,2.526V0.522c0-0.2,0.115-0.384,0.293-0.469c0.18-0.087,0.396-0.066,0.552,0.061l15.47,12.202c0.123,0.1,0.195,0.253,0.195,0.409c0,0.16-0.072,0.311-0.195,0.411L5.316,25.34c-0.155,0.125-0.372,0.147-0.552,0.061C4.586,25.315,4.471,25.13,4.471,24.929z"/></symbol><symbol id="icon-star" viewBox="0 0 48 48"><path fill="currentColor" d="M44,24c0,11.045-8.955,20-20,20S4,35.045,4,24S12.955,4,24,4S44,12.955,44,24z"/><path fill="#ffffff" d="M24,11l3.898,7.898l8.703,1.301l-6.301,6.102l1.5,8.699L24,30.898L16.199,35l1.5-8.699l-6.301-6.102  l8.703-1.301L24,11z"/></symbol><symbol id="icon-read" viewBox="0 0 32 32"><path fill="currentColor" d="M29,4H3C1.343,4,0,5.343,0,7v18c0,1.657,1.343,3,3,3h10c0,0.552,0.448,1,1,1h4c0.552,0,1-0.448,1-1h10  c1.657,0,3-1.343,3-3V7C32,5.343,30.657,4,29,4z M29,5v20H18.708c-0.618,0-1.236,0.146-1.789,0.422l-0.419,0.21V5H29z M15.5,5  v20.632l-0.419-0.21C14.528,25.146,13.91,25,13.292,25H3V5H15.5z M31,25c0,1.103-0.897,2-2,2H18v1h-4v-1H3c-1.103,0-2-0.897-2-2V7  c0-0.737,0.405-1.375,1-1.722V25c0,0.552,0.448,1,1,1h10.292c0.466,0,0.925,0.108,1.342,0.317l0.919,0.46  c0.141,0.07,0.294,0.106,0.447,0.106c0.153,0,0.306-0.035,0.447-0.106l0.919-0.46C17.783,26.108,18.242,26,18.708,26H29  c0.552,0,1-0.448,1-1V5.278C30.595,5.625,31,6.263,31,7V25z M6,12.5C6,12.224,6.224,12,6.5,12h5c0.276,0,0.5,0.224,0.5,0.5  S11.776,13,11.5,13h-5C6.224,13,6,12.776,6,12.5z M6,14.5C6,14.224,6.224,14,6.5,14h5c0.276,0,0.5,0.224,0.5,0.5S11.776,15,11.5,15  h-5C6.224,15,6,14.776,6,14.5z M6,16.5C6,16.224,6.224,16,6.5,16h5c0.276,0,0.5,0.224,0.5,0.5S11.776,17,11.5,17h-5  C6.224,17,6,16.776,6,16.5z M20,12.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,13,25.5,13h-5  C20.224,13,20,12.776,20,12.5z M20,14.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,15,25.5,15h-5  C20.224,15,20,14.776,20,14.5z M20,16.5c0-0.276,0.224-0.5,0.5-0.5h5c0.276,0,0.5,0.224,0.5,0.5S25.776,17,25.5,17h-5  C20.224,17,20,16.776,20,16.5z"></path></symbol></defs></svg>

        <header class="bar-header">
    <a id="menu" role="button">
        <svg id="open" class="icon-menu"><use xlink:href="#icon-menu"></use></svg>
    </a>
    <h1 class="logo">
        <a href="/nebula/">
            
                A Sétima Nébula <span class="version">v3.1.2</span>
            
        </a>
    </h1>
    <a id="search" class="dosearch" role="button">
        <svg class="icon-search"><use xlink:href="#icon-search"></use></svg>
    </a>
    
</header>

<div id="mask" class="overlay"></div>

<aside class="sidebar" id="sidebar">
    <nav id="navigation">
      <h2>Menu</h2>
      <ul>
  
    
      <li>
        <a href="/nebula/">Home</a>
      </li>
    
  
    
      <li>
        <a href="/nebula/sobre">Sobre</a>
      </li>
    
  
</ul>

    </nav>
</aside>

<div class="search-wrapper">
    <div class="search-form">
        <input type="text" class="search-field" placeholder="Pesquisar">
        <svg class="icon-remove-sign"><use xlink:href="#icon-close"></use></svg>
        <ul class="search-results search-list"></ul>
    </div>
</div>



        <section class="post two-columns">
            <article role="article" class="post-content">
                <p class="post-info">
                    
                        <svg class="icon-calendar" id="date"><use xlink:href="#icon-calendar"></use></svg>
                        <time class="date" datetime="2024-05-12T20:46:31+00:00">
                            


12 de Maio, 2024

                        </time>
                    
                    <svg id="clock" class="icon-clock"><use xlink:href="#icon-clock"></use></svg>
                    <span>15 min.</span>
                </p>
                <h1 class="post-title">Hadoop: Elefantes amarelos, Clusters e Fagulhas</h1>
                <p class="post-subtitle"></p>

                
                    <img src="https://i.imgur.com/mEgc9jG.jpeg" alt="Featured image" class="post-cover">
                

                <!-- Pagination links -->



                <!-- Add your table of contents here -->


                <p>O Hadoop é um assunto paradoxal dentro do campo de Engenharia de Dados. Como atual estudante da área, vejo que muito se fala sobre o Apache Spark e a sua mágica velocidade de processamento, mas pouco se fala do Hadoop como a base sobre a qual o Spark foi criado. Ao mesmo tempo, múltiplas soluções ofertadas por ambientes de nuvem utilizadas para execução de tarefas do Spark, muitas vezes não são vendidas apenas como ambientes para o Spark, mas sim para ferramentas do ecossistema Hadoop. Então, qual a sacada do Hadoop? Qual sua importância? E ele ainda é relevante?</p>

<p>De uma maneira inicial, o Hadoop é uma plataforma open source, desenvolvida em Java, de armazenamento e processamento de dados para aplicações de Big Data, utilizando para isso o poder da computação distribuída. Ou seja, ao invés de processar os dados em um único computador, o Hadoop utiliza um grupo de computadores, geralmente chamado de <em>cluster</em>, para a execução de tarefas, que são divididas adequadamente entre cada um dos computadores, geralmente chamados de <em>nós</em>. Através dessa divisão, múltiplas sub-tarefas são executadas ao mesmo tempo, diminuindo o tempo da execução como um todo. É literalmente “dividir para conquistar” usando computadores.</p>

<p>Bem, pelo menos esse era o conceito do Hadoop. Veremos que ao longo dos anos ele parece ter mudado um pouco.</p>

<h2 id="história">História</h2>
<p>O desenvolvimento do Hadoop se iniciou em 2002 com dois desenvolvedores, Doug Cutting e Mike Cafarella, que trabalhavam em um projeto chamado Apache Nutch. A ideia do Nutch era de basicamente criar um sistema de mecanismo de buscas de páginas da web capaz de processar uma quantidade muito grande de dados, semelhante ao que hoje é encontrado por trás do portal de pesquisas do Google. Entretanto, após muita pesquisa, percebeu-se que o projeto era economicamente inviável, requerendo uma imensa quantidade de dinheiro em hardware para mantê-lo, especialmente quando se considerava o armazenamento e o processamento dos dados.</p>

<p>Estes dois problemas foram superados através da inspiração em duas tecnologias divulgadas via artigo pelo Google: o Google File System (GFS), solução para armazenamento de grandes quantidades de dados, e o MapReduce, que é uma tecnologia para processamento massivo de dados. A partir dessas ideias, o único obstáculo que ainda permanecia para o desenvolvimento do Nutch era mão de obra. Logo, buscando investimento para o seu projeto, Doug Cutting se junta ao Yahoo, onde encontrou um time de engenheiros que o ajudou a definitivamente criar a solução. Durante esse processo, Cutting separou o módulo de processamento de dados do restante do projeto, criando um novo projeto batizado de Hadoop, nome que veio de um elefante amarelo de brinquedo que pertencia ao seu filho.</p>

<p><img src="https://i.imgur.com/TpdZZCC.png" alt="Fonte: Wired, 2023" />
<em>Fonte: Wired, 2023.</em></p>

<p>Em 2008, o Hadoop foi lançado como um projeto Open Source através da Apache Software Foundation, uma organização sem fins lucrativos voltada para a divulgação e suporte de projetos Open Source, o que democratizou a várias empresas o acesso a um poder computacional de alta capacidade de processamento só disponível na época através de soluções proprietárias que dominavam o mercado.</p>

<h2 id="arquitetura-principal">Arquitetura Principal</h2>
<p><img src="https://i.imgur.com/EtjCAvu.jpg" alt="Fonte: Quora, 2020." />
<em>Fonte: Quora, 2020.</em></p>

<p>A Arquitetura Principal do Hadoop, o que poderíamos chamar do seu núcleo, é composto de quatro elementos:</p>

<ul>
  <li><em>Hadoop Distributed File System (HDFS)</em>: Sistema de armazenamento distribuído entre os vários nós de um cluster Hadoop, permitindo o seu processamento em paralelo por vários dispositivos, ao mesmo tempo que garante uma alta tolerância à falhas.</li>
  <li><em>MapReduce</em>: Sistema responsável pelo processamento de dados do Hadoop, onde operações são mapeadas aos dados distribuídos (Map) e os resultados de todas as operações são agregados em um único valor final (Reduce).</li>
  <li><em>Yet Another Resource Negotiator (YARN)</em>: Sistema para gerenciamento de recursos, planejamento e agendamento de tarefas no cluster.</li>
  <li><em>Hadoop Commons</em>: Conjunto de serviços e utilitários que oferecem suporte a outros módulos do Hadoop.</li>
</ul>

<h2 id="hdfs">HDFS</h2>
<p>O HDFS é um sistema de arquivos distribuído construído para armazenar grandes quantidade de dados operando eficientemente em hardware de baixo custo e garantindo a disponibilidade dos dados através de mecanismos de tolerância a falhas. Para entender cada pedaço dessa frase, vale a pena visitar o funcionamento interno do HDFS.</p>

<p><img src="https://i.imgur.com/asY9nvx.png" alt="Fonte: InterviewBit, 2024." />
<em>Fonte: InterviewBit, 2024.</em></p>

<p>A arquitetura do HDFS funciona através de um sistema Mestre-Servidor, ou seja, há um elemento central que controla vários outros elementos “subordinados”. Trazendo para o mundo do Hadoop, esses elementos são:</p>

<ul>
  <li><em>Name Node</em>: Opera como o mestre do sistema, gerenciando os arquivos e provisionando o seu acesso por usuários. Para isso, ele assume algumas importantes responsabilidades.
    <ul>
      <li>Primeiro, ele é responsável por distribuir os dados entre os vários nós do sistema. Para isso, um arquivo único é separado em pedaços chamados de blocos, e cada um desses blocos é alocado em diferentes nós do cluster. É como se cada arquivo fosse quebrado em pequenas peças de LEGO. Essas peças são guardadas em locais separados, mas podem ser juntadas novamente para formar o arquivo original.</li>
      <li>Segundo, ele armazena metadados. Metadados são basicamente informações relevantes sobre os dados que estão sendo armazenados no sistema. Podem envolver desde informações básicas como nome do arquivo, data de criação e seu tamanho, até informações mais específicas do sistema, como quantidade de blocos de um arquivo e a localização destes blocos no cluster. Isso é importante pois, quando um determinado arquivo precisar ser lido do HDFS, os seus blocos devem ser reunidos para reconstruir o arquivo original e assim devolvê-lo ao usuário que o requisitou. Precisamos saber onde os blocos de LEGO se encontram para montar o arquivo. E o Name Node contém essa informação.</li>
      <li>E por fim, o Name Node é o responsável por realizar operações sobre estes blocos, como criar, deletar, renomear, replicar, entre outros e sobre arquivos e diretórios, como abertura, fechamento e renomeação.</li>
    </ul>
  </li>
  <li><em>Data Node</em>: Opera como o servidor do sistema, estando presente em cada nó do cluster. São responsáveis basicamente por armazenar os blocos de dados alocados pelo Name Node, servir operações de leitura e escrita dos clientes, e atender operações sobre os blocos requisitadas pelo Name Node.</li>
</ul>

<p>A partir desta separação de um arquivo em múltiplos blocos armazenados em diferentes computadores, o HDFS consegue criar um sistema propício para o armazenamento de uma grande quantidade de dados. Mas como dito no início dessa seção, esse sistema foi desenvolvido para funcionar em máquinas comuns e de baixo custo, e essas máquinas podem naturalmente falhar. Assim, para tomar isso em conta, e evitar que dados sejam perdidos, o HDFS promove uma tolerância a estas possíveis falhas replicando dados. Ou seja, cada bloco de dados separado pelo Name Node é alocado em mais de um Data Node. Dessa forma, caso um nó do cluster falhe, algum outro nó ainda existente vai conter um dado que estava no nó que falhou, e assim nada é perdido. No caso do HDFS, cada bloco é por padrão replicado 3 vezes, ou seja, uma mesma informação é salva em 3 locais diferentes. Isso obviamente leva a um consumo maior de armazenamento, e portanto a mais custos, porém são custos justificados pela segurança de armazenamento dos dados.</p>

<p><img src="https://i.imgur.com/yrVSslC.png" alt="Fonte: Hdfstutorial, 2016." />
<em>Fonte: Hdfstutorial, 2016.</em></p>

<p>Com isso, riscamos o checklist do HDFS:</p>

<ul>
  <li>
    <p><del>Armazenamento para grandes quantidade de Dados</del></p>
  </li>
  <li>
    <p><del>Operação em Hardware Comum e de Baixo Custo</del></p>
  </li>
  <li>
    <p><del>Tolerante à Falhas</del></p>
  </li>
</ul>

<h2 id="mapreduce">MapReduce</h2>
<p>O MapReduce é a ferramenta de processamento de dados original do Hadoop, sendo responsável por ler os dados do HDFS, processá-los seguindo algum script, e devolver o resultado ao HDFS. Arquiteturalmente, uma das principais características do MapReduce é o fato de que a sua execução é feita no mesmo local onde os dados estão armazenados. Ou seja, se um determinado arquivo deve ser processado pelo MapReduce, cada um dos seus blocos será processado no mesmo nó do cluster em que ele já se encontra, não necessitando de movimentação de blocos entre os dispositivos, o que torna o sistema mais performático.</p>

<p>Um dos princípios centrais do MapReduce é realizar todo esse processo abstraindo a complexidade dos dados distribuídos (como visto na seção anterior) para o usuário, que se preocupa em apenas definir dois tipos principais de operações, que dão o nome à ferramenta.</p>

<p><img src="https://i.imgur.com/O2Zahxb.png" alt="Fonte: DataScientest, 2023." />
<em>Fonte: DataScientest, 2023.</em></p>

<ul>
  <li>Map: Consiste em uma função aplicada aos blocos de dados, que já se encontram separados no HDFS. Os Mappers recebem os dados em um formato &lt;chave,valor&gt; e o seu resultado também gera um novo conjunto de &lt;chave,valor&gt;.</li>
  <li>Reduce: Os resultados das operações de Map ainda se encontram distribuídos nos nós do cluster, e o Reduce é a operação responsável por agregá-los e gerar o resultado final da tarefa. Os resultados intermediários com a mesma chave são enviados para o mesmo Reducer.</li>
</ul>

<p>Além dessas duas funções principais, existem algumas funções intermediárias entre o Map e o Reduce, que possuem um impacto positivo na performance do sistema:</p>

<ul>
  <li>Shuffle: Redistribuição de dados entre os nós, agregando informações com a mesma chave em um mesmo nó.</li>
  <li>Combine: Operação opcional, onde um reducer é executado em cada mapper, de forma a reduzir ainda mais os seus resultados antes de serem transmitidos, reduzindo a carga de dados a serem trafegados.</li>
  <li>Partition: Processo que decide como os dados resultantes do Map serão apresentados para o Reducer.</li>
</ul>

<h2 id="yarn">YARN</h2>
<p>E para gerenciar tudo isso, temos o YARN, que é o módulo do Hadoop responsável pelo gerenciamento de recursos, planejamento e agendamento de tarefas. Dito de uma maneira mais simples, o YARN recebe as tarefas a serem executadas no cluster e aloca para cada uma quantidade de máquinas do cluster necessários para sua execução no momento em que elas forem agendadas para serem executadas.</p>

<p>Em termos de arquitetura, o YARN se localiza entre o HDFS e a ferramenta de processamento, utilizando um gerenciador de recursos centralizado e gerenciadores de recurso em cada nó de forma a alocar os devidos recursos (representados em slots chamados de containers) para cada aplicação, cuja execução é garantida por um gerenciador específico.</p>

<p><img src="https://i.imgur.com/MtpDCRf.png" alt="Fonte: TechTarget, 2018." />
<em>Fonte: TechTarget, 2018.</em></p>

<p>Atualmente o Hadoop se encontra em sua terceira versão, e o YARN foi adicionado apenas a partir da segunda versão. Na primeira versão do Hadoop, essas funcionalidades de gerenciamento de recursos e agendamento de tarefas eram feitos pelo próprio MapReduce, o que limitava o Hadoop a executar apenas aplicações MapReduce. Com a adição do YARN, entretanto, o gerenciamento de recursos e o processamento dos dados em si foram desacoplados, abrindo portas para que outros sistemas, além do MapReduce, pudessem ser utilizados junto ao Hadoop. Isso transformou o Hadoop de uma ferramenta única para o que ele é hoje: Um ecossistema.</p>

<h2 id="ecossistema-hadoop">Ecossistema Hadoop</h2>
<p>Hoje em dia, o MapReduce já não é uma ferramenta muito utilizada, pelo menos diretamente. Com a flexibilidade criada pelo YARN, algumas outras ferramentas surgiram no mercado, trazendo mais funcionalidades e interfaces mais intuitivas para o MapReduce, ou em alguns casos, até o substituindo como ferramenta de processamento. Isso transformou o Hadoop de uma simples ferramenta única para um ambiente, onde várias soluções que utilizam o processamento de dados em paralelo como base podem ser encontradas. Obviamente algumas são mais populares do que outras, e vale a pena visitá-las brevemente.</p>

<p><img src="https://i.imgur.com/fMXQbv1.png" alt="Fonte: Medium, 2023." />
<em>Fonte: Medium, 2023.</em></p>

<h3 id="hive">Hive</h3>
<p><img src="https://i.imgur.com/atHzQ4m.png" alt="Fonte: Wikipedia, 2022." />
<em>Fonte: Wikipedia, 2022.</em></p>

<p>O Apache Hive é uma solução de data warehouse open source criada pelo Facebook, capaz de ler, escrever e gerenciar dados em grande escala. Sua ideia principal é a de utilizar o Hadoop como base para processamento e armazenamento de dados, mas fornecendo uma interface de interação muito mais fácil e flexível através de uma linguagem de sintaxe muito semelhante ao SQL. Isso permitiu que diversos engenheiros pudessem utilizar o processamento do Hadoop de uma maneira muito mais ágil, visto que profissionais com conhecimentos em SQL eram muito mais comuns do que profissionais com conhecimento em Java, a única linguagem através da qual os jobs MapReduce podiam ser definidos.</p>

<p>Além disso, o Hive trouxe como uma importante decisão de design um elemento central responsável por armazenar metadados, realizando o mapeamento entre os arquivos do HDFS e as devidas tabelas do Hive.</p>

<h3 id="pig">Pig</h3>
<p><img src="https://i.imgur.com/gDmPYz3.png" alt="Fonte: Wikipedia, 2022." />
<em>Fonte: Wikipedia, 2022.</em></p>

<p>O Apache Pig, semelhante ao Hive, é uma ferramenta que funciona sobre o Hadoop, fornecendo uma interface de programação mais simples e de alto nível. A diferença, entretanto, é que o Pig possui uma natureza mais voltada para processos de extração, limpeza e pré-processamento dos dados, enquanto o Hive é mais utilizado para a análise e operações de dados já transformados. De certa forma, as duas ferramentas podem ser utilizadas de maneira complementar: Enquanto o Pig pode ser utilizado para extração, limpeza e organização dos dados, o Hive pode ser utilizado para analisar os dados entregues pelo Pig.</p>

<h3 id="hbase">HBase</h3>

<p><img src="https://i.imgur.com/OXe4Avv.png" alt="Fonte: AWS,2023." />
<em>Fonte: AWS,2023.</em></p>

<p>O HBase é um banco de dados NoSQL, open source e distribuído que assim como as demais ferramentas apresentadas, opera sobre o Hadoop. Utilizando sua arquitetura distribuída, o HBase escala linearmente para lidar com cojuntos de dados envolvendo bilhões de linhas e milhões de colunas.</p>

<h3 id="spark">Spark</h3>
<p><img src="https://i.imgur.com/dCtIiYO.png" alt="Fonte: DataScienceAcademy, 2020." />
<em>Fonte: DataScienceAcademy, 2020.</em></p>

<p>O Spark é uma ferramenta de processamento de dados, criada através de um projeto de pesquisa da Universidade da Califórnia, que foi criado com o objetivo de acelerar a execução de tarefas no Hadoop. Isso foi alcançado principalmente através da mudança de local de armazenamento dos dados a serem processados: Enquanto o MapReduce utilizava o disco, o Spark passou a utilizar a memória, que é um componente muito mais otimizado para o acesso rápido de informações pelo processador.</p>

<p>Além disso, o Spark trouxe uma maior flexibilidade de uso como ferramenta, tanto em termos de cenários, onde pode ser utilizado para processamentos em Lote (vários dados processados de uma vez) ou em Streaming (dados processados quase em tempo real), além de possuir interface para várias linguagens de programação. Soma-se a isso submódulos extras, que permitem interações com os dados via uma interface SQL, desenvolvimento de modelos de Machine Learning e processamento de Grafos.</p>

<p><img src="https://i.imgur.com/p242ITL.png" alt="Fonte: Medium, 2021." />
<em>Fonte: Medium, 2021.</em></p>

<p>Diferentemente das outras ferramentas apresentadas, o Spark se encaixa no Hadoop realmente substituindo o MapReduce como ferramenta de processamento. E principalmente devido aos exorbitantes resultados de velocidade obtidos, chegando a ser 100 vezes mais rápido do que o MapReduce, o Spark veio, em anos recentes, tomando o espaço do MapReduce como escolha em diversas arquiteturas de dados de grande volume, tornando-se uma ferramenta extremamente popular hoje em dia e o motor principal de processamento de dados em muitos Data Lakes por aí. O que nos leva a perguntar…</p>

<h2 id="onde-está-o-elefante">Onde está o Elefante?</h2>
<p>Além da já citada supremacia do Apache Spark sobre o MapReduce, o Hadoop como ferramenta também perdeu outra liderança: a de armazenamento. Com a flexibilidade trazida pelas novas ferramentas do ecossistema, vieram também a compatibilidade com sistemas de armazenamento diferentes do HDFS, trazendo vantagens como custos mais baixos, maior segurança e alta disponibilidade dos dados. Além disso, com o aumento da disponibilidade e velocidade da internet hoje em dia, surgiu a tendência de separar o armazenamento e o processamento dos dados em sistemas diferentes, ao contrário do que prega o HDFS de juntar essas duas dimensões no mesmo dispositivo. Parece contraintuitivo, mas isso trouxe importantes facilidades, principalmente para a escalabilidade do sistema.</p>

<p>Tudo isso fez com que o HDFS caisse em desuso, sendo substituído por outros sistemas em decisões de arquitetura, como os Object Storages, que dominam as estruturas de Data Lakes hoje em dia.</p>

<p>E com isso, o Hadoop foi destronado nos dois principais pilares em que foi criado: Processamento e Armazenamento.</p>

<h2 id="então-ele-morreu">Então, ele morreu?</h2>
<p><img src="https://i.imgur.com/jjbS8uL.png" alt="Fonte: LinkedIn, 2019." />
<em>Fonte: LinkedIn, 2019.</em></p>

<p>Alguns dizem que o Hadoop morreu. O elefante já era. Bem, eu acho que depende.</p>

<p>Como a ferramenta de processamento de dados criada lá trás para armazenar e processar dados em larga escala, sim talvez ele tenha morrido mesmo. Mas como conceito, acho que ele não morreu, só se transformou em outra coisa. Se transformou em uma plataforma onde alguns de seus princípios, como o uso de licenças open source, adaptação para hardware simples e sua natureza modular permitiu a criação de inúmeras ferramentas importantes, das quais algumas dominam o mercado de dados e são escolha para muitas arquiteturas de dados por aí.</p>

<p>Então de certa forma, de uma maneira indireta, o Hadoop ainda está meio vivo. O elefante está por aí, só um pouco escondido nos diagramas de arquitetura.</p>

<h2 id="referências">Referências</h2>
<p><a href="https://www.geeksforgeeks.org/hadoop-history-or-evolution/">Hadoop | History or Evolution por GeeksbyGeeks</a></p>

<p><a href="https://www.databricks.com/br/glossary/hadoop">O que é Hadoop? por Databricks</a></p>

<p><a href="https://www.techtarget.com/searchdatamanagement/definition/Apache-Hadoop-YARN-Yet-Another-Resource-Negotiator#:~:text=One%20of%20Apache%20Hadoop's%20core,executed%20on%20different%20cluster%20nodes">Apache Hadoop YARN por TechTarget</a></p>

<p><a href="https://www.databricks.com/glossary/hadoop-distributed-file-system-hdfs">Hadoop Distributed File System (HDFS) por Databricks</a></p>

<p><a href="https://www.geeksforgeeks.org/hadoop-architecture/">Hadoop - Architecture por GeeksbyGeeks</a></p>

<p><a href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html">HDFS Architecture Guide por Hadoop</a></p>

<p><a href="https://www.databricks.com/glossary/apache-hive">What is Apache Hive? por Databricks</a></p>

<p><a href="https://www.udemy.com/course/gcp-data-engineer-and-cloud-architect">GCP: Complete Google Data Engineer and Cloud Architect Guide por Udemy</a></p>

<p><a href="https://cetax.com.br/o-que-e-o-apache-hbase/">Apache HBase: O que é, Conceitos e Definições por Cetax</a></p>

<p><a href="https://medium.com/@acmurthy/hadoop-is-dead-long-live-hadoop-f22069b264ac">Hadoop is Dead. Long live Hadoop. por Arun C Murthy</a></p>


                <!-- Pagination links -->


            </article>

            
                <aside class="see-also">
                    <h2>Veja Também</h2>
                    <ul>
                        
                        
                        
                            <li>
                                <a href="/nebula/intelig%C3%AAncia-em-m%C3%A1quinas/">
                                    
                                        <img src="https://i.imgur.com/yRAALVi.png">
                                    
                                    <h3>Inteligência. Em Máquinas.</h3>
                                </a>
                            </li>
                        
                            <li>
                                <a href="/nebula/a-dieta-do-machine-learning/">
                                    
                                        <img src="https://i.imgur.com/GNK6lbi.png">
                                    
                                    <h3>A dieta do Machine Learning</h3>
                                </a>
                            </li>
                        
                            <li>
                                <a href="/nebula/vetores/">
                                    
                                        <img src="https://i.imgur.com/hmiLBuz.png">
                                    
                                    <h3>Vetores</h3>
                                </a>
                            </li>
                        
                    </ul>
                </aside>
            

        </section>

        <!-- Add time bar only for pages without pagination -->
        

        <!-- Show modal if the post is the last one -->
        

        <!-- Show modal before user leaves the page -->
        

        <!-- Add your newsletter subscription form here -->

        

  <section class="author">
    <div class="details">
      
        <img class="img-rounded" src="../assets/img/uploads/andre.jpeg" alt="André Machado">
      
      <p class="def">Autor</p>
      <h3 class="name">
        <a href="/authors/andre-ls/">André Machado</a>
      </h3>
      <p class="desc">Engenheiro de Dados de pouca data, músico e gamer de RPGs.</p>
      <p>
        
          <a href="https://github.com/andre-ls" title="Github">
            <svg><use xlink:href="#icon-github"></use></svg>
          </a>
        
        
        
        
        
        
          <a href="https://www.linkedin.com/in/andrélamachado" title="LinkedIn">
            <svg><use xlink:href="#icon-linkedin"></use></svg>
          </a>
        
      </p>
    </div>
  </section>

  
  
  
  
  
  
  

  <script type="application/ld+json">
  {
      "@context": "http://schema.org",
      "@type": "Person",
      "name": "André Machado",
      
      "image": "../assets/img/uploads/andre.jpeg",
      
      "jobTitle": "Engenheiro de Dados",
      "url": "/nebula/authors/andre-ls/",
      "sameAs": [
        "https://github.com/andre-ls","https://www.linkedin.com/in/andrélamachado"
      ]
  }
  </script>


        

        <footer>
    <p>
      
        <a href="https://github.com/andre-ls" title="Github">
          <svg><use xlink:href="#icon-github"></use></svg>
        </a>
      
      
      
      
      
      
        <a href="https://www.linkedin.com/in/andrélamachado" title="LinkedIn">
          <svg><use xlink:href="#icon-linkedin"></use></svg>
        </a>
      
    </p>

    <ul>
  
    
      <li>
        <a href="/nebula/">Home</a>
      </li>
    
  
    
      <li>
        <a href="/nebula/sobre">Sobre</a>
      </li>
    
  
</ul>


    <p>
      <span>Jekflix</span> was made with <svg class="love"><use xlink:href="#icon-heart"></use></svg> by <a href="https://rossener.com" target="_blank" class="creator">Thiago Rossener</a>
    </p>
</footer>









<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "A Sétima Nébula",
  "description": "A Sétima Nébula é um blog contendo artigos sobre temas relacionados à Engenharia de Dados, escritos de uma maneira simples e intuitiva.",
  "url": "/nebula/",
  "logo": {
      "@type": "ImageObject",
      "url": "/nebula/assets/img/icons/mediumtile.png",
      "width": "600",
      "height": "315"
  },
  "sameAs": [
    "https://github.com/andre-ls","https://www.linkedin.com/in/andrélamachado"
  ]
}
</script>

<!-- Include the script that allows Netlify CMS login -->
<script src="https://identity.netlify.com/v1/netlify-identity-widget.js"></script>

<!-- Include the website scripts -->
<script src="/nebula/assets/js/scripts.min.js"></script>

<!-- Include Google Analytics script -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-XXXXXXXX-X"></script>
<script>
  var host = window.location.hostname;
  if (host != 'localhost') {
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-XXXXXXXX-X');
  }
</script>
  


<!-- Include extra scripts -->



        

        
        
        
        
        
        
        
        
        <script type="application/ld+json">
        {
            "@context": "http://schema.org",
            "@type": "BlogPosting",
            "name": "Hadoop: Elefantes amarelos, Clusters e Fagulhas",
            "headline": "",
            "description": "",
            "image": "https://i.imgur.com/mEgc9jG.jpeg",
            "url": "/nebula/hadoop-elefantes-amarelos,-clusters-e-fagulhas/",
            "articleBody": "O Hadoop é um assunto paradoxal dentro do campo de Engenharia de Dados. Como atual estudante da área, vejo que muito se fala sobre o Apache Spark e a sua mágica velocidade de processamento, mas pouco se fala do Hadoop como a base sobre a qual o Spark foi criado. Ao mesmo tempo, múltiplas soluções ofertadas por ambientes de nuvem utilizadas para execução de tarefas do Spark, muitas vezes não são vendidas apenas como ambientes para o Spark, mas sim para ferramentas do ecossistema Hadoop. Então, qual a sacada do Hadoop? Qual sua importância? E ele ainda é relevante?

De uma maneira inicial, o Hadoop é uma plataforma open source, desenvolvida em Java, de armazenamento e processamento de dados para aplicações de Big Data, utilizando para isso o poder da computação distribuída. Ou seja, ao invés de processar os dados em um único computador, o Hadoop utiliza um grupo de computadores, geralmente chamado de cluster, para a execução de tarefas, que são divididas adequadamente entre cada um dos computadores, geralmente chamados de nós. Através dessa divisão, múltiplas sub-tarefas são executadas ao mesmo tempo, diminuindo o tempo da execução como um todo. É literalmente “dividir para conquistar” usando computadores.

Bem, pelo menos esse era o conceito do Hadoop. Veremos que ao longo dos anos ele parece ter mudado um pouco.

História
O desenvolvimento do Hadoop se iniciou em 2002 com dois desenvolvedores, Doug Cutting e Mike Cafarella, que trabalhavam em um projeto chamado Apache Nutch. A ideia do Nutch era de basicamente criar um sistema de mecanismo de buscas de páginas da web capaz de processar uma quantidade muito grande de dados, semelhante ao que hoje é encontrado por trás do portal de pesquisas do Google. Entretanto, após muita pesquisa, percebeu-se que o projeto era economicamente inviável, requerendo uma imensa quantidade de dinheiro em hardware para mantê-lo, especialmente quando se considerava o armazenamento e o processamento dos dados.

Estes dois problemas foram superados através da inspiração em duas tecnologias divulgadas via artigo pelo Google: o Google File System (GFS), solução para armazenamento de grandes quantidades de dados, e o MapReduce, que é uma tecnologia para processamento massivo de dados. A partir dessas ideias, o único obstáculo que ainda permanecia para o desenvolvimento do Nutch era mão de obra. Logo, buscando investimento para o seu projeto, Doug Cutting se junta ao Yahoo, onde encontrou um time de engenheiros que o ajudou a definitivamente criar a solução. Durante esse processo, Cutting separou o módulo de processamento de dados do restante do projeto, criando um novo projeto batizado de Hadoop, nome que veio de um elefante amarelo de brinquedo que pertencia ao seu filho.


Fonte: Wired, 2023.

Em 2008, o Hadoop foi lançado como um projeto Open Source através da Apache Software Foundation, uma organização sem fins lucrativos voltada para a divulgação e suporte de projetos Open Source, o que democratizou a várias empresas o acesso a um poder computacional de alta capacidade de processamento só disponível na época através de soluções proprietárias que dominavam o mercado.

Arquitetura Principal

Fonte: Quora, 2020.

A Arquitetura Principal do Hadoop, o que poderíamos chamar do seu núcleo, é composto de quatro elementos:


  Hadoop Distributed File System (HDFS): Sistema de armazenamento distribuído entre os vários nós de um cluster Hadoop, permitindo o seu processamento em paralelo por vários dispositivos, ao mesmo tempo que garante uma alta tolerância à falhas.
  MapReduce: Sistema responsável pelo processamento de dados do Hadoop, onde operações são mapeadas aos dados distribuídos (Map) e os resultados de todas as operações são agregados em um único valor final (Reduce).
  Yet Another Resource Negotiator (YARN): Sistema para gerenciamento de recursos, planejamento e agendamento de tarefas no cluster.
  Hadoop Commons: Conjunto de serviços e utilitários que oferecem suporte a outros módulos do Hadoop.


HDFS
O HDFS é um sistema de arquivos distribuído construído para armazenar grandes quantidade de dados operando eficientemente em hardware de baixo custo e garantindo a disponibilidade dos dados através de mecanismos de tolerância a falhas. Para entender cada pedaço dessa frase, vale a pena visitar o funcionamento interno do HDFS.


Fonte: InterviewBit, 2024.

A arquitetura do HDFS funciona através de um sistema Mestre-Servidor, ou seja, há um elemento central que controla vários outros elementos “subordinados”. Trazendo para o mundo do Hadoop, esses elementos são:


  Name Node: Opera como o mestre do sistema, gerenciando os arquivos e provisionando o seu acesso por usuários. Para isso, ele assume algumas importantes responsabilidades.
    
      Primeiro, ele é responsável por distribuir os dados entre os vários nós do sistema. Para isso, um arquivo único é separado em pedaços chamados de blocos, e cada um desses blocos é alocado em diferentes nós do cluster. É como se cada arquivo fosse quebrado em pequenas peças de LEGO. Essas peças são guardadas em locais separados, mas podem ser juntadas novamente para formar o arquivo original.
      Segundo, ele armazena metadados. Metadados são basicamente informações relevantes sobre os dados que estão sendo armazenados no sistema. Podem envolver desde informações básicas como nome do arquivo, data de criação e seu tamanho, até informações mais específicas do sistema, como quantidade de blocos de um arquivo e a localização destes blocos no cluster. Isso é importante pois, quando um determinado arquivo precisar ser lido do HDFS, os seus blocos devem ser reunidos para reconstruir o arquivo original e assim devolvê-lo ao usuário que o requisitou. Precisamos saber onde os blocos de LEGO se encontram para montar o arquivo. E o Name Node contém essa informação.
      E por fim, o Name Node é o responsável por realizar operações sobre estes blocos, como criar, deletar, renomear, replicar, entre outros e sobre arquivos e diretórios, como abertura, fechamento e renomeação.
    
  
  Data Node: Opera como o servidor do sistema, estando presente em cada nó do cluster. São responsáveis basicamente por armazenar os blocos de dados alocados pelo Name Node, servir operações de leitura e escrita dos clientes, e atender operações sobre os blocos requisitadas pelo Name Node.


A partir desta separação de um arquivo em múltiplos blocos armazenados em diferentes computadores, o HDFS consegue criar um sistema propício para o armazenamento de uma grande quantidade de dados. Mas como dito no início dessa seção, esse sistema foi desenvolvido para funcionar em máquinas comuns e de baixo custo, e essas máquinas podem naturalmente falhar. Assim, para tomar isso em conta, e evitar que dados sejam perdidos, o HDFS promove uma tolerância a estas possíveis falhas replicando dados. Ou seja, cada bloco de dados separado pelo Name Node é alocado em mais de um Data Node. Dessa forma, caso um nó do cluster falhe, algum outro nó ainda existente vai conter um dado que estava no nó que falhou, e assim nada é perdido. No caso do HDFS, cada bloco é por padrão replicado 3 vezes, ou seja, uma mesma informação é salva em 3 locais diferentes. Isso obviamente leva a um consumo maior de armazenamento, e portanto a mais custos, porém são custos justificados pela segurança de armazenamento dos dados.


Fonte: Hdfstutorial, 2016.

Com isso, riscamos o checklist do HDFS:


  
    Armazenamento para grandes quantidade de Dados
  
  
    Operação em Hardware Comum e de Baixo Custo
  
  
    Tolerante à Falhas
  


MapReduce
O MapReduce é a ferramenta de processamento de dados original do Hadoop, sendo responsável por ler os dados do HDFS, processá-los seguindo algum script, e devolver o resultado ao HDFS. Arquiteturalmente, uma das principais características do MapReduce é o fato de que a sua execução é feita no mesmo local onde os dados estão armazenados. Ou seja, se um determinado arquivo deve ser processado pelo MapReduce, cada um dos seus blocos será processado no mesmo nó do cluster em que ele já se encontra, não necessitando de movimentação de blocos entre os dispositivos, o que torna o sistema mais performático.

Um dos princípios centrais do MapReduce é realizar todo esse processo abstraindo a complexidade dos dados distribuídos (como visto na seção anterior) para o usuário, que se preocupa em apenas definir dois tipos principais de operações, que dão o nome à ferramenta.


Fonte: DataScientest, 2023.


  Map: Consiste em uma função aplicada aos blocos de dados, que já se encontram separados no HDFS. Os Mappers recebem os dados em um formato &amp;lt;chave,valor&amp;gt; e o seu resultado também gera um novo conjunto de &amp;lt;chave,valor&amp;gt;.
  Reduce: Os resultados das operações de Map ainda se encontram distribuídos nos nós do cluster, e o Reduce é a operação responsável por agregá-los e gerar o resultado final da tarefa. Os resultados intermediários com a mesma chave são enviados para o mesmo Reducer.


Além dessas duas funções principais, existem algumas funções intermediárias entre o Map e o Reduce, que possuem um impacto positivo na performance do sistema:


  Shuffle: Redistribuição de dados entre os nós, agregando informações com a mesma chave em um mesmo nó.
  Combine: Operação opcional, onde um reducer é executado em cada mapper, de forma a reduzir ainda mais os seus resultados antes de serem transmitidos, reduzindo a carga de dados a serem trafegados.
  Partition: Processo que decide como os dados resultantes do Map serão apresentados para o Reducer.


YARN
E para gerenciar tudo isso, temos o YARN, que é o módulo do Hadoop responsável pelo gerenciamento de recursos, planejamento e agendamento de tarefas. Dito de uma maneira mais simples, o YARN recebe as tarefas a serem executadas no cluster e aloca para cada uma quantidade de máquinas do cluster necessários para sua execução no momento em que elas forem agendadas para serem executadas.

Em termos de arquitetura, o YARN se localiza entre o HDFS e a ferramenta de processamento, utilizando um gerenciador de recursos centralizado e gerenciadores de recurso em cada nó de forma a alocar os devidos recursos (representados em slots chamados de containers) para cada aplicação, cuja execução é garantida por um gerenciador específico.


Fonte: TechTarget, 2018.

Atualmente o Hadoop se encontra em sua terceira versão, e o YARN foi adicionado apenas a partir da segunda versão. Na primeira versão do Hadoop, essas funcionalidades de gerenciamento de recursos e agendamento de tarefas eram feitos pelo próprio MapReduce, o que limitava o Hadoop a executar apenas aplicações MapReduce. Com a adição do YARN, entretanto, o gerenciamento de recursos e o processamento dos dados em si foram desacoplados, abrindo portas para que outros sistemas, além do MapReduce, pudessem ser utilizados junto ao Hadoop. Isso transformou o Hadoop de uma ferramenta única para o que ele é hoje: Um ecossistema.

Ecossistema Hadoop
Hoje em dia, o MapReduce já não é uma ferramenta muito utilizada, pelo menos diretamente. Com a flexibilidade criada pelo YARN, algumas outras ferramentas surgiram no mercado, trazendo mais funcionalidades e interfaces mais intuitivas para o MapReduce, ou em alguns casos, até o substituindo como ferramenta de processamento. Isso transformou o Hadoop de uma simples ferramenta única para um ambiente, onde várias soluções que utilizam o processamento de dados em paralelo como base podem ser encontradas. Obviamente algumas são mais populares do que outras, e vale a pena visitá-las brevemente.


Fonte: Medium, 2023.

Hive

Fonte: Wikipedia, 2022.

O Apache Hive é uma solução de data warehouse open source criada pelo Facebook, capaz de ler, escrever e gerenciar dados em grande escala. Sua ideia principal é a de utilizar o Hadoop como base para processamento e armazenamento de dados, mas fornecendo uma interface de interação muito mais fácil e flexível através de uma linguagem de sintaxe muito semelhante ao SQL. Isso permitiu que diversos engenheiros pudessem utilizar o processamento do Hadoop de uma maneira muito mais ágil, visto que profissionais com conhecimentos em SQL eram muito mais comuns do que profissionais com conhecimento em Java, a única linguagem através da qual os jobs MapReduce podiam ser definidos.

Além disso, o Hive trouxe como uma importante decisão de design um elemento central responsável por armazenar metadados, realizando o mapeamento entre os arquivos do HDFS e as devidas tabelas do Hive.

Pig

Fonte: Wikipedia, 2022.

O Apache Pig, semelhante ao Hive, é uma ferramenta que funciona sobre o Hadoop, fornecendo uma interface de programação mais simples e de alto nível. A diferença, entretanto, é que o Pig possui uma natureza mais voltada para processos de extração, limpeza e pré-processamento dos dados, enquanto o Hive é mais utilizado para a análise e operações de dados já transformados. De certa forma, as duas ferramentas podem ser utilizadas de maneira complementar: Enquanto o Pig pode ser utilizado para extração, limpeza e organização dos dados, o Hive pode ser utilizado para analisar os dados entregues pelo Pig.

HBase


Fonte: AWS,2023.

O HBase é um banco de dados NoSQL, open source e distribuído que assim como as demais ferramentas apresentadas, opera sobre o Hadoop. Utilizando sua arquitetura distribuída, o HBase escala linearmente para lidar com cojuntos de dados envolvendo bilhões de linhas e milhões de colunas.

Spark

Fonte: DataScienceAcademy, 2020.

O Spark é uma ferramenta de processamento de dados, criada através de um projeto de pesquisa da Universidade da Califórnia, que foi criado com o objetivo de acelerar a execução de tarefas no Hadoop. Isso foi alcançado principalmente através da mudança de local de armazenamento dos dados a serem processados: Enquanto o MapReduce utilizava o disco, o Spark passou a utilizar a memória, que é um componente muito mais otimizado para o acesso rápido de informações pelo processador.

Além disso, o Spark trouxe uma maior flexibilidade de uso como ferramenta, tanto em termos de cenários, onde pode ser utilizado para processamentos em Lote (vários dados processados de uma vez) ou em Streaming (dados processados quase em tempo real), além de possuir interface para várias linguagens de programação. Soma-se a isso submódulos extras, que permitem interações com os dados via uma interface SQL, desenvolvimento de modelos de Machine Learning e processamento de Grafos.


Fonte: Medium, 2021.

Diferentemente das outras ferramentas apresentadas, o Spark se encaixa no Hadoop realmente substituindo o MapReduce como ferramenta de processamento. E principalmente devido aos exorbitantes resultados de velocidade obtidos, chegando a ser 100 vezes mais rápido do que o MapReduce, o Spark veio, em anos recentes, tomando o espaço do MapReduce como escolha em diversas arquiteturas de dados de grande volume, tornando-se uma ferramenta extremamente popular hoje em dia e o motor principal de processamento de dados em muitos Data Lakes por aí. O que nos leva a perguntar…

Onde está o Elefante?
Além da já citada supremacia do Apache Spark sobre o MapReduce, o Hadoop como ferramenta também perdeu outra liderança: a de armazenamento. Com a flexibilidade trazida pelas novas ferramentas do ecossistema, vieram também a compatibilidade com sistemas de armazenamento diferentes do HDFS, trazendo vantagens como custos mais baixos, maior segurança e alta disponibilidade dos dados. Além disso, com o aumento da disponibilidade e velocidade da internet hoje em dia, surgiu a tendência de separar o armazenamento e o processamento dos dados em sistemas diferentes, ao contrário do que prega o HDFS de juntar essas duas dimensões no mesmo dispositivo. Parece contraintuitivo, mas isso trouxe importantes facilidades, principalmente para a escalabilidade do sistema.

Tudo isso fez com que o HDFS caisse em desuso, sendo substituído por outros sistemas em decisões de arquitetura, como os Object Storages, que dominam as estruturas de Data Lakes hoje em dia.

E com isso, o Hadoop foi destronado nos dois principais pilares em que foi criado: Processamento e Armazenamento.

Então, ele morreu?

Fonte: LinkedIn, 2019.

Alguns dizem que o Hadoop morreu. O elefante já era. Bem, eu acho que depende.

Como a ferramenta de processamento de dados criada lá trás para armazenar e processar dados em larga escala, sim talvez ele tenha morrido mesmo. Mas como conceito, acho que ele não morreu, só se transformou em outra coisa. Se transformou em uma plataforma onde alguns de seus princípios, como o uso de licenças open source, adaptação para hardware simples e sua natureza modular permitiu a criação de inúmeras ferramentas importantes, das quais algumas dominam o mercado de dados e são escolha para muitas arquiteturas de dados por aí.

Então de certa forma, de uma maneira indireta, o Hadoop ainda está meio vivo. O elefante está por aí, só um pouco escondido nos diagramas de arquitetura.

Referências
Hadoop | History or Evolution por GeeksbyGeeks

O que é Hadoop? por Databricks

Apache Hadoop YARN por TechTarget

Hadoop Distributed File System (HDFS) por Databricks

Hadoop - Architecture por GeeksbyGeeks

HDFS Architecture Guide por Hadoop

What is Apache Hive? por Databricks

GCP: Complete Google Data Engineer and Cloud Architect Guide por Udemy

Apache HBase: O que é, Conceitos e Definições por Cetax

Hadoop is Dead. Long live Hadoop. por Arun C Murthy
",
            "wordcount": "2852",
            "inLanguage": "pt-BR",
            "dateCreated": "2024-05-12/",
            "datePublished": "2024-05-12/",
            "dateModified": "2024-05-12/",
            "author": {
                "@type": "Person",
                "name": "André Machado",
                
                "image": "../assets/img/uploads/andre.jpeg",
                
                "jobTitle": "Engenheiro de Dados",
                "url": "/nebula/authors/andre-ls/",
                "sameAs": [
                    "https://github.com/andre-ls","https://www.linkedin.com/in/andrélamachado"
                ]
            },
            "publisher": {
                "@type": "Organization",
                "name": "A Sétima Nébula",
                "url": "/nebula/",
                "logo": {
                    "@type": "ImageObject",
                    "url": "/nebula/assets/img/blog-image.png",
                    "width": "600",
                    "height": "315"
                }
            },
            "mainEntityOfPage": "True",
            "genre": "",
            "articleSection": "",
            "keywords": ["hadoop","bigdata","spark"]
        }
        </script>
    </body>
</html>
