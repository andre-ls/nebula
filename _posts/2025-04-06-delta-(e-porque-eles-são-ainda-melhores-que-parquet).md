---
date: 2025-04-06 19:04:12
layout: post
title: "Delta (e porque eles s√£o ainda melhores que Parquet)"
subtitle:
description:
image: https://i.imgur.com/LZUQJqy.jpeg
optimized_image:
category:
tags: delta acid logs
author: andre-ls
paginate: false
---
Os arquivos Parquet, assim como explorei em um artigo passado, s√£o boas solu√ß√µes para armazenar dados e acess√°-los de maneira eficiente, atendendo assim diversas necessidades do mundo de solu√ß√µes anal√≠ticas. Mas ainda existe algo, que estes arquivos n√£o oferecem, mas que s√£o encontrados aos montes em bancos de dados tradicionais:  V√°rios mecanismos e garantias de consist√™ncia e durabilidade que d√£o aos seus usu√°rios o conforto de que os seus dados dificilmente ser√£o perdidos ou corrompidos, e de que ser√£o acessados e alterados de maneira consistente. 

E na tentativa de trazer estas funcionalidades (e mais algumas outras) para o armazenamento atrav√©s de arquivos, surgiram algumas ferramentas que subiram na garupa dos Parquet e outros formatos de arquivo e adicionaram mais capacidades ao mesmo, tornando-os ainda mais robustos. Uma dessas ferramentas, talvez a pioneira nesse aspecto, e o personagem principal deste artigo, √© o Delta Lake.

## Delta Lake = Parquet + ???

O Delta Lake √© um framework open-source para armazenamento de dados em arquivos que traz uma grande quantidade de vantagens e novas funcionalidades que s√£o ausentes em arquivos puramente Parquet, e ainda mais em arquivos csv os xlsx. A sua documenta√ß√£o oficial cita coisas como transa√ß√µes ACID, Time Travel, gerenciamento de schema e algumas outras usando v√°rios nomes e conceitos um pouco t√©cnicos demais. Vamos dar um passo atr√°s, come√ßar simples e focar no essencial.

O Delta Lake, na sua ess√™ncia mais b√°sica poss√≠vel, consiste na jun√ß√£o de dois tipos de arquivos:

- Arquivos Parquet, respons√°veis pelo armazenamento de dados, com todas os seus potenciais para isso.
- Arquivos JSON, onde s√£o armazenados diversos logs sobre as opera√ß√µes realizadas sobre os dados, al√©m de metadados.

![image.png](https://i.imgur.com/CIcmtlp.png)
*Arquivos Parquet e JSON.*

Cada opera√ß√£o realizada em um conjunto de dados gera uma nova vers√£o de cada um destes arquivos. Tanto uma nova vers√£o dos dados √© criada, quanto um novo arquivo de logs, contendo informa√ß√µes sobre a √∫ltima opera√ß√£o realizada. 

![image.png](https://i.imgur.com/ssjnQyd.png)
*Versionamento de Arquivos.*

Os arquivos de logs podem conter v√°rias informa√ß√µes, mas essencialmente, as suas principais envolvem:

- Opera√ß√£o realizada no conjunto de dados.
- Organiza√ß√£o das colunas do conjunto de dados (popularmente conhecida como schema).
- Quais arquivos, dentre as v√°rias vers√µes armazenadas, representam a vers√£o atual dos dados.

E os arquivos Parquet, bem‚Ä¶contem os dados, em suas mais diversas vers√µes. √â interessante perceber que mesmo uma opera√ß√£o de dele√ß√£o de registros n√£o apaga arquivos de dados, mas na verdade, acaba criando uma nova vers√£o. 

Mas ent√£o, se s√£o dois tipos de arquivos (e n√£o um s√≥) e v√°rias vers√µes, como se d√° o processo de leitura e escrita de dados destes arquivos?

## Leitura e Escrita

Basicamente toda leitura inicia consultando os logs contidos no arquivo JSON visando obter duas informa√ß√µes:

- Onde est√£o os arquivos que representam a vers√£o mais recente dos dados.
- E quais s√£o as colunas e formatos dessa vers√£o.

A partir destas informa√ß√µes, o processo de leitura se direciona ao arquivo especificado e realiza a leitura, como qualquer outro arquivo Parquet. 

![image.png](https://i.imgur.com/TBArvwr.png)
*Processo de Leitura.*

J√° a escrita, acontece seguindo o caminho reverso. Primeiro, uma nova vers√£o dos dados √© gerada, e se ela for escrita com sucesso, uma nova vers√£o dos logs √© constru√≠da, fornecendo as informa√ß√µes da nova vers√£o dos dados. 

![image.png](https://i.imgur.com/l1Vg1ff.png)
*Processo de Escrita.*

A princ√≠pio, a gest√£o destes dois tipos de arquivos torna as coisas um pouco mais complexas. Mas  ao mesmo tempo, √© a simples jun√ß√£o destes dois arquivos e as informa√ß√µes que eles armazenam que formam a base de pelo menos algumas das funcionalidades que o Delta Lake promete. E nesses cen√°rios, os ganhos superam os custos.

## Transa√ß√µes ACID

Talvez a mais importante caracter√≠stica trazida pelo Delta Lake seja a no√ß√£o de transa√ß√µes e todas as suas garantias, trazidas na sigla ACID, que significa:

- Atomicidade: Esse termo se refere ao fato de que cada opera√ß√£o ou conjunto de opera√ß√µes  a ser realizada no conjunto de dados √© indivis√≠vel. De uma maneira menos t√©cnica, a ideia aqui √© que ou a opera√ß√£o √© conclu√≠da totalmente com sucesso ou ela √© inteiramente cancelada. N√£o existe meio termo.
- Consist√™ncia: Garante que as opera√ß√µes nos dados sejam feitas de maneira consistente, evitando erros e corrup√ß√µes que possam comprometer os dados.
- Isolamento: Garante que cada transa√ß√£o seja tratada de forma isolada umas das outras, mesmo em situa√ß√µes onde dois usu√°rios possam estar atuando ao mesmo tempo no mesmo conjunto de dados.
- Durabilidade: Bem, garante que ap√≥s uma transa√ß√£o ser finalizada, os seus dados sejam gravados no sistema, mesmo em caso de falha do sistema. Basicamente isso.

Novamente, um monte de termos complexos. Vamos tentar mostrar como cada ponto desse √© atendido a partir de mais desenhos.

Primeiro Atomicidade. Vimos na se√ß√£o anterior que qualquer leitura aos dados se inicia com uma consulta aos logs, para ent√£o ser direcionada aos devidos arquivos. Considerando isso, podemos concluir que se um determinado arquivo n√£o existe nos logs, ele nunca poder√° ser lido por algu√©m. E √© esse o racioc√≠nio utilizado pelo Delta para garantir a Atomicidade: Se ocorrer uma falha durante um processo de altera√ß√£o dos dados que gere uma nova vers√£o, basta n√£o registrar o novo arquivo gerados nos logs, tornando-o inacess√≠vel. 

![image.png](https://i.imgur.com/7aBtqNT.png)
*Atomicidade funcionando, do ponto de vista dos logs.*

Do ponto de vista do usu√°rio, entende-se que todas as opera√ß√µes de um determinado conjunto falharam, e n√£o foram aplicadas aos dados, que √© justamente a ideia da atomicidade. Com isso, Atomicidade ‚úÖ.

Pr√≥ximo, Consist√™ncia. Esse termo pode se referir a muitas coisas, mas do ponto de vista de dados, o principal √© garantir a consist√™ncia do Schema. Schema √© um termo t√©cnico utilizado para se referenciar basicamente √† organiza√ß√£o de uma tabela, o que envolve a defini√ß√£o de quais colunas ela cont√©m e quais os tipos dessas colunas (texto, n√∫mero inteiro, n√∫mero decimal, data, etc.). As informa√ß√µes sobre o Schema se encontram nos logs do Delta Lake, e garantir a consist√™ncia disso se resume a simplesmente garantir que novos dados que sejam adicionados sigam esse padr√£o de colunas. 

![image.png](https://i.imgur.com/JVRvEnQ.png)
*Consist√™ncia de Dados*

E √≥bvio, se o usu√°rio deseja mudar o Schema de uma tabela, √© poss√≠vel. Basta que ele declare isso nas opera√ß√µes, e o Delta gerencia todo o resto, inclusive atualizando as informa√ß√µes nos logs e garantido assim a consist√™ncia das pr√≥ximas opera√ß√µes com o novo formato criado. Assim, Consist√™ncia ‚úÖ.

Isolamento. Bem, talvez esse seja o mais complexo de explicar, mas o Delta Lake o resolve de uma maneira at√© que elegante. O Isolamento garante que dois ou mais usu√°rios podem operar sobre os mesmos dados sem influenciar ou atrapalhar uns aos outros. Cada uma de suas opera√ß√µes √© tratada de maneira isolada. E os logs e as v√°rias vers√µes de arquivos existentes ajudam nisso. 

Vamos exemplificar com o simples cen√°rio onde temos dois usu√°rios operando ao mesmo tempo sob o mesmo conjunto de dados, onde um est√° tentando ler a vers√£o mais atual dos dados, enquanto outro est√° inserindo novos registros, e consequentemente gerando uma nova vers√£o.

O usu√°rio que est√° inserindo novos registros inicia o seu processo, criando uma nova vers√£o de arquivos a partir da √∫ltima vers√£o dispon√≠vel. Mas como o processo ainda n√£o foi finalizado, a nova vers√£o gerada ainda n√£o foi registrada nos logs. Enquanto isso, o usu√°rio que deseja ler os dados inicia seu processo pela consulta dos logs, procurando saber quais arquivos refletem a vers√£o atual dos dados. E aqui se encontra o principal detalhe: Para quais arquivos, os logs v√£o direcionar a leitura do usu√°rio? A √∫ltima vers√£o salva do arquivo ou a nova vers√£o que est√° sendo escrita pelo outro usu√°rio no mesmo momento?

Seguindo todo o racioc√≠nio explicado at√© agora, n√£o √© muito dif√≠cil concluir que os logs apontar√£o para a √∫ltima vers√£o salva do arquivo, porque a nova vers√£o que est√° sendo gerada ainda n√£o foi finalizada e registrada nos logs para leitura. Somente ap√≥s isso acontecer, novas opera√ß√µes de leitura apontar√£o para a nova vers√£o gerada.

![image.png](https://i.imgur.com/pQzHtMj.png)
*Isolamento de Opera√ß√µes.*

Dessa forma, como pode ser visto na imagem acima, cada usu√°rio opera em arquivos totalmente diferentes, e com isso, as opera√ß√µes s√£o totalmente isoladas umas das outras. Isolamento ‚úÖ.

Por fim, Durabilidade. Este √∫ltimo t√≥pico, na pr√°tica, depende muito mais da estrutura onde os dados s√£o armazenados do que do pr√≥prio funcionamento interno do Delta Lake. E isso, por sua vez, depende de como o usu√°rio utiliza o Delta Lake, e em qual arquitetura ele se encaixa. Mas, considerando o cen√°rio mais comum encontrado hoje nas corpora√ß√µes, dados s√£o armazenados comumente em sistemas de armazenamento na nuvem, que n√£o s√≥ possuem altos n√≠veis de disponibilidade, mas que apresentam v√°rios mecanismos de seguran√ßa nos raros casos de falha, garantindo que os dados n√£o sejam corrompidos ou perdidos. E assim garante-se a Durabilidade ‚úÖ.

Dessa forma, o Delta Lake garante todas as quatro letras do ACID, e pode-se perceber que os logs e o versionamento de dados atuam em boa parte delas. Mas n√£o √© s√≥ isso. Essas ferramentas ainda entregam uma outra importante funcionalidade.

## Viagem no Tempo e Evolu√ß√£o

Vimos que o Delta Lake gera v√°rias vers√µes, tanto para os dados como para os logs. E tudo bem, estas vers√µes s√£o importantes para o funcionamento principalmente do Isolamento e da Atomicidade. Mas seria de certa forma um desperd√≠cio se os pr√≥prios usu√°rios tamb√©m n√£o pudessem utiliz√°-las. 

Dessa forma, o Delta permite aos seus usu√°rios ‚Äúviajar no tempo‚Äù e tanto consultar vers√µes antigas dos dados, como tamb√©m restaurar os dados a vers√µes anteriores quando necess√°rio. 

![image.png](https://i.imgur.com/yUGDEjA.png)
*Viagem no Tempo e consulta √† vers√¥es antigas.*

Al√©m disso, todo os arquivos de logs formam um hist√≥rico de todas as opera√ß√µes realizadas sob um determinado conjunto de dados, servindo como um prato cheio para diversas aplica√ß√µes de auditorias.

## E as vantagens continuam‚Ä¶

Nesse artigo, quis focar nas vantagens principais do Delta Lake e em como ele utiliza os seus arquivos e logs para alcan√ß√°-las. E s√≥ com isso, o texto j√° ficou um pouco extenso. Mas os benef√≠cios que o Delta Lake traz ainda continuam por uma longa lista: otimiza√ß√£o de consultas e organiza√ß√£o de arquivos, integra√ß√£o com processos de streaming e valida√ß√µes de qualidade dos dados s√£o alguns, dentre outros, que podem ser encontrados na sua documenta√ß√£o e em outros artigos por a√≠. 

Tamb√©m vale a pena mencionar que al√©m do Delta Lake, existem outras ferramentas no mercado que ocupam a mesma prateleira, como o Apache Hudi e o Apache Iceberg, trazendo diversas facilidades e garantias para o armazenamento de dados anal√≠ticos em arquivos.

Espero que este artigo n√£o tenha ficado muito longo e dif√≠cil de ler, e que possa ajuda algu√©m üôÇ

## Refer√™ncias

[Delta Lake 101 Part 2: Transaction Log por seeQuality](https://pl.seequality.net/delta-lake-101-part-2-transaction-log/)

[What are ACID guarantees on Databricks? por Databricks](https://docs.databricks.com/aws/en/lakehouse/acid)

[Um guia para propriedades ACID em sistemas de gerenciamento de banco de dados por MongoDB](https://www.mongodb.com/pt-br/resources/basics/databases/acid-transactions#:~:text=transactions%20are%20required.-,ACID%20transactions,the%20event%20of%20unexpected%20errors)

[Databricks Certified Data Engineer Associate - Preparation por Derar Alhussein](https://www.udemy.com/course/databricks-certified-data-engineer-associate/)
